{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install PyGithub python-dotenv pandas tqdm aiohttp asyncio bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "from github import Github, Commit, Repository\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from datetime import datetime, timezone\n",
    "import pytz\n",
    "from random import randint\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "GITHUB_TOKEN = getenv('GITHUB_TOKEN')\n",
    "g = Github(GITHUB_TOKEN, per_page=100)\n",
    "cutoff_date = datetime(2024, 9, 19, tzinfo=pytz.UTC)\n",
    "session = aiohttp.ClientSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(repo: Repository, path: str):\n",
    "    try:\n",
    "        return repo.get_contents(path).decoded_content.decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting {path}'s content from {repo.full_name}: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RawData:\n",
    "    full_path: str\n",
    "    timestamp: datetime\n",
    "    sha: str\n",
    "    message: str\n",
    "    diff: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def close_session():\n",
    "    await session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_diff(repo, sha: str, retries: int=6):\n",
    "    diff_url = f'https://github.com/{repo.full_name}/commit/{sha}.diff'\n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_TOKEN}',\n",
    "        'Accept': 'application/vnd.github.v3.diff'\n",
    "    }\n",
    "\n",
    "    backoff = 2\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for attempt in range(retries):\n",
    "            await asyncio.sleep(randint(9, 18))\n",
    "            try:\n",
    "                async with session.get(diff_url, headers=headers, timeout=aiohttp.ClientTimeout(total=30)) as response:\n",
    "                    remaining_requests = response.headers.get('X-RateLimit-Remaining')\n",
    "                    \n",
    "                    if response.status == 200:\n",
    "                        return await response.text()\n",
    "                    elif response.status == 403:  # Rate limit likely hit\n",
    "                        reset_time_utc = datetime.fromtimestamp(int(response.headers.get('X-RateLimit-Reset')), tz=timezone.utc)\n",
    "                        sao_paulo_tz = pytz.timezone('America/Sao_Paulo')\n",
    "                        reset_time_sao_paulo = reset_time_utc.astimezone(sao_paulo_tz)\n",
    "                        print(f\"Rate limit hit: {remaining_requests} remaining, resetting at {reset_time_sao_paulo.isoformat()}\")\n",
    "                        wait_time = max(1, (reset_time_utc - datetime.now(timezone.utc)).total_seconds() + 1)\n",
    "                        await asyncio.sleep(wait_time)\n",
    "                    elif response.status == 429:  # Too many requests, wait 60 seconds\n",
    "                        print(f\"Rate limit hit, waiting 60 seconds (attempt {attempt + 1})\")\n",
    "                        await asyncio.sleep(60)\n",
    "                    else:\n",
    "                        print(f\"Attempt {attempt + 1} | Error {response.status} | Remaining: {remaining_requests}\")\n",
    "                        await asyncio.sleep(backoff)\n",
    "                        backoff *= 2\n",
    "            except aiohttp.ClientConnectorError as e:\n",
    "                print(f\"Attempt {attempt + 1} | Connection error: {e}\")\n",
    "                await asyncio.sleep(backoff)\n",
    "                backoff *= 2\n",
    "            except asyncio.TimeoutError:\n",
    "                print(f\"Attempt {attempt + 1} | Request timed out.\")\n",
    "                await asyncio.sleep(backoff)\n",
    "                backoff *= 2\n",
    "\n",
    "    return \"Max retries exceeded. Please try again later.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_commit(repo: Repository, commit: Commit, cutoff_date: datetime) -> None:\n",
    "    if commit.commit.author.date < cutoff_date:\n",
    "        diff = await get_diff(repo, commit.sha)\n",
    "        message = commit.commit.message\n",
    "        timestamp = commit.commit.author.date.isoformat()\n",
    "        sha = commit.sha\n",
    "        full_path = f'{repo.owner.login}/{repo.name}'\n",
    "        rawDataObj = RawData(full_path, timestamp, sha, message, diff)\n",
    "        return sha, rawDataObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repos = [('spring-guides', 'gs-accessing-data-jpa'), ('Azure-Samples', 'java-native-telemetry'),\n",
    "#         ('aws-samples', 'amazon-ivs-player-web-sample'), \n",
    "#         ('aws-samples', 'aws-marketplace-serverless-saas-integration')]\n",
    "repos = pd.read_csv('code_samples.csv', skiprows=1)[:14]\n",
    "\n",
    "repos = repos.dropna(subset=['html_url'])\n",
    "\n",
    "raw_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "for repo in tqdm(repos.iterrows(), total=len(repos), desc=\"Processing repositories\"):\n",
    "    repo_ecosystem = repo[1]['html_url'].split('/')[-2]\n",
    "    repo_obj = g.get_organization(repo_ecosystem).get_repo(repo[1]['name'])\n",
    "    commits = list(repo_obj.get_commits())\n",
    "    for commit in commits:\n",
    "        # Task for processing each commit\n",
    "        task = asyncio.create_task(process_commit(repo_obj, commit, cutoff_date))\n",
    "        tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_with_concurrency(n, *coros):\n",
    "    semaphore = asyncio.Semaphore(n)\n",
    "    print(f\"Semaphore: {semaphore}\")\n",
    "\n",
    "    async def no_coro(coro):\n",
    "        async with semaphore:\n",
    "            try:\n",
    "                return await coro\n",
    "            except Exception as e:\n",
    "                print(f\"Task failed with error: {e}\")\n",
    "                return None\n",
    "    \n",
    "    return [no_coro(coro) for coro in coros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_tasks = await gather_with_concurrency(8, *tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress bar\n",
    "for future in tqdm(asyncio.as_completed(limited_tasks), total=len(tasks), desc=\"Processing commits\"):\n",
    "    result = await future\n",
    "    if result:\n",
    "        sha, rawDataObj = result\n",
    "        raw_data[sha] = rawDataObj\n",
    "\n",
    "await close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = open('raw_data.pkl', 'wb')\n",
    "pickle.dump(raw_data, p)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([vars(v) for v in raw_data.values()])\n",
    "df.to_csv('raw_data.csv', index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
